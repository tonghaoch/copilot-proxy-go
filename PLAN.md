# Copilot Proxy Go â€” Implementation Plan

> A Go rewrite of [caozhiyuan/copilot-api](https://github.com/caozhiyuan/copilot-api/tree/all).
> Turns GitHub Copilot into an OpenAI / Anthropic compatible API server.

## Status Legend

- â¬œ Not started
- ðŸ”¨ In progress
- âœ… Completed
- â­ï¸ Skipped

---

## Phase 1 â€” Core Foundation

> Goal: A working server that can authenticate with GitHub, fetch models, and proxy
> one translation path (Chat Completions passthrough) end-to-end.

| # | Feature | Status | Notes |
|---|---------|--------|-------|
| 1.1 | Project scaffolding (`go.mod`, directory structure, `main.go`) | âœ… | chi + cobra |
| 1.2 | Global state management (tokens, models, config, flags) | âœ… | Singleton with sync.RWMutex |
| 1.3 | File system paths (`~/.local/share/copilot-api/`) | âœ… | `EnsurePaths()` |
| 1.4 | GitHub OAuth device-code flow (client ID, scope `read:user`) | âœ… | |
| 1.5 | Device code polling with interval | âœ… | With slow_down handling |
| 1.6 | GitHub token persistence to disk | âœ… | `0600` permissions |
| 1.7 | Copilot token fetch (`GET /copilot_internal/v2/token`) | âœ… | |
| 1.8 | Copilot token auto-refresh timer | âœ… | Goroutine with `refresh_in - 60s` |
| 1.9 | User identity logging (`GET /user`) | âœ… | |
| 1.10 | Dynamic Copilot base URL per account type | âœ… | individual/business/enterprise |
| 1.11 | VS Code version fetching (AUR scrape + hardcoded fallback) | âœ… | 5s timeout, regex parse |
| 1.12 | Copilot request headers builder (User-Agent, editor-version, etc.) | âœ… | |
| 1.13 | `X-Initiator` header (agent/user) | âœ… | |
| 1.14 | `x-request-id: {uuid}` per request | âœ… | google/uuid |
| 1.15 | HTTP server setup (e.g. `net/http` + router like `chi` or `echo`) | âœ… | go-chi/chi v5 |
| 1.16 | Request logging middleware | âœ… | slog-based |
| 1.17 | CORS middleware | âœ… | go-chi/cors |
| 1.18 | Health check `GET /` â†’ "Server running" | âœ… | |
| 1.19 | `GET /models` + `/v1/models` â€” model listing | âœ… | |
| 1.20 | Model capabilities parsing & caching at startup | âœ… | |
| 1.21 | `GET /models` service â€” fetch from Copilot API | âœ… | |
| 1.22 | `POST /chat/completions` + `/v1/chat/completions` â€” passthrough | âœ… | |
| 1.23 | `max_tokens` auto-fill from model capabilities | âœ… | |
| 1.24 | Agent/user initiator detection (chat completions) | âœ… | Last message role check |
| 1.25 | Non-streaming response passthrough | âœ… | |
| 1.26 | SSE streaming passthrough | âœ… | bufio.Scanner + http.Flusher |
| 1.27 | `HTTPError` type + `forwardError` utility | âœ… | JSON error parsing |
| 1.28 | `GET /token` â€” expose current Copilot bearer token | âœ… | |
| 1.29 | Basic `start` command (port, github-token, account-type flags only) | âœ… | +verbose, +show-token |

**Milestone**: Can authenticate, list models, and proxy OpenAI Chat Completions requests.

---

## Phase 2 â€” Full API Translation

> Goal: Support all 3 backend routing paths for the Anthropic Messages endpoint,
> plus the OpenAI Responses and Embeddings endpoints.

### 2A â€” Anthropic Messages â†’ Chat Completions Backend

| # | Feature | Status | Notes |
|---|---------|--------|-------|
| 2.1 | `POST /v1/messages` route registration | âœ… | messages.go |
| 2.2 | 3-way backend routing logic (messages/responses/chat-completions) | âœ… | Based on `supported_endpoints` |
| 2.3 | System prompt translation (string or array â†’ system message) | âœ… | ParseSystemPrompt helper |
| 2.4 | Extra prompt injection from config per model | âœ… | Wired, config integration Phase 3 |
| 2.5 | User message translation (split tool_result into tool role) | âœ… | translateUserMessage |
| 2.6 | Assistant message translation (tool_use â†’ tool_calls, thinking â†’ reasoning) | âœ… | translateAssistantMessage |
| 2.7 | Image content handling (base64 â†’ data URI) | âœ… | buildUserContent |
| 2.8 | Tool definition translation (input_schema â†’ parameters) | âœ… | translateTools |
| 2.9 | Tool choice translation (auto/any/tool/none) | âœ… | translateToolChoice |
| 2.10 | Model name normalization (strip version suffixes) | âœ… | normalizeModelName |
| 2.11 | Non-streaming response translation (OpenAI â†’ Anthropic) | âœ… | translateToAnthropic |
| 2.12 | Stop reason mapping (stopâ†’end_turn, etc.) | âœ… | mapStopReason |
| 2.13 | Streaming translation â€” state machine (SSE chunks â†’ Anthropic events) | âœ… | AnthropicStreamState |
| 2.14 | Thinking text streaming as thinking blocks | âœ… | reasoning_text handling |
| 2.15 | Reasoning opaque streaming with placeholder + signature | âœ… | Self-contained opaque blocks |
| 2.16 | Tool call streaming with `input_json_delta` | âœ… | ToolCallDelta handling |
| 2.17 | Multi-tool-call streaming state | âœ… | toolCallMap tracking |
| 2.18 | Usage / cache token passthrough | âœ… | CacheReadInputTokens |
| 2.19 | Error event translation | âœ… | TranslateErrorEvent |
| 2.20 | Interleaved thinking protocol injection | âœ… | XML prompt + system-reminder |
| 2.21 | Thinking budget calculation (clamp min/max) | âœ… | clampThinkingBudget |
| 2.22 | Thinking block filtering for Claude models | âœ… | Empty, "Thinking...", `@` filter |
| 2.23 | Edge cases: content after thinking, reasoning_text during content block | âœ… | Copilot bug workarounds |
| 2.24 | `copilot-vision-request: true` header when images detected | âœ… | All backends |
| 2.25 | `"Thinking..."` placeholder for opencode compatibility | âœ… | Default thinking text |
| 2.26 | Cache read token separation (Anthropic billing model) | âœ… | InputTokens - CachedTokens |

### 2B â€” Anthropic Messages â†’ Responses API Backend

| # | Feature | Status | Notes |
|---|---------|--------|-------|
| 2.27 | Full message/tool/system â†’ Responses format translation | âœ… | translateToResponses |
| 2.28 | Temperature forced to 1 for reasoning models | âœ… | |
| 2.29 | `max_output_tokens` minimum 12800 | âœ… | |
| 2.30 | Reasoning effort from config | âœ… | Default "high", config Phase 3 |
| 2.31 | Reasoning config (`include`, `store`, `parallel_tool_calls`) | âœ… | |
| 2.32 | User ID parsing for `safety_identifier` + `prompt_cache_key` | âœ… | parseUserIDIntoPayload |
| 2.33 | Codex phase assignment (`commentary`/`final_answer` for gpt-5.3-codex) | âœ… | |
| 2.34 | Thinking block â†’ reasoning item conversion (signature `@` encoding) | âœ… | SplitN on `@` |
| 2.35 | Tool result â†’ `function_call_output` conversion | âœ… | is_error â†’ "incomplete" |
| 2.36 | Image content â†’ `input_image` conversion | âœ… | buildResponsesContent |
| 2.37 | Non-streaming Responses â†’ Anthropic translation | âœ… | translateResponsesResultToAnthropic |
| 2.38 | Streaming Responses â†’ Anthropic SSE translation | âœ… | ResponsesStreamState |
| 2.39 | Infinite whitespace detection guard (20 char limit) | âœ… | wsRunLength tracking |
| 2.40 | Stream completion detection | âœ… | messageCompleted flag |
| 2.41 | Function call argument parsing with fallback | âœ… | parseToolInput (array/raw fallback) |

### 2C â€” Native Messages API Passthrough

| # | Feature | Status | Notes |
|---|---------|--------|-------|
| 2.42 | Direct forwarding for models supporting `/v1/messages` | âœ… | handleWithMessagesAPI |
| 2.43 | Thinking block filtering before forwarding | âœ… | filterThinkingBlocks |
| 2.44 | Adaptive thinking support with effort mapping | âœ… | applyAdaptiveThinking |
| 2.45 | `anthropic-beta` header filtering (remove `claude-code-20250219`) | âœ… | filterBetaHeader |
| 2.46 | `anthropic-beta` auto-injection for thinking | âœ… | |
| 2.47 | Vision detection + header | âœ… | hasVision + header |
| 2.48 | Streaming / non-streaming passthrough | âœ… | Direct SSE forwarding |

### 2D â€” OpenAI Responses Endpoint (Passthrough)

| # | Feature | Status | Notes |
|---|---------|--------|-------|
| 2.49 | `POST /responses` + `/v1/responses` route | âœ… | |
| 2.50 | Model support validation (400 if unsupported) | âœ… | |
| 2.51 | `apply_patch` custom tool â†’ function tool conversion | âœ… | convertApplyPatchTools |
| 2.52 | `web_search` tool removal | âœ… | removeWebSearchTools |
| 2.53 | Stream ID synchronization (fix `@ai-sdk/openai` crashes) | âœ… | StreamIDSync |
| 2.54 | `service_tier` nullification | âœ… | |
| 2.55 | Vision detection in Responses payloads | âœ… | containsImageRecursive |
| 2.56 | Agent initiator detection (Responses) | âœ… | detectAgentInResponses |
| 2.57 | Non-streaming / streaming passthrough | âœ… | With stream ID sync |

### 2E â€” Embeddings Endpoint

| # | Feature | Status | Notes |
|---|---------|--------|-------|
| 2.58 | `POST /embeddings` + `/v1/embeddings` route | âœ… | |
| 2.59 | Embeddings passthrough to Copilot | âœ… | |

**Milestone**: Full Anthropic Messages API compatibility with all 3 backends,
plus OpenAI Responses and Embeddings passthrough.

---

## Phase 3 â€” Optimizations & Utilities

> Goal: Quota-saving logic, rate limiting, token counting, logging, and config system.

### 3A â€” Configuration System

| # | Feature | Status | Notes |
|---|---------|--------|-------|
| 3.1 | JSON config file (`config.json`) auto-creation with defaults | âœ… | `chmod 0600` |
| 3.2 | `auth.apiKeys` config option | âœ… | Normalized, deduplicated |
| 3.3 | `extraPrompts` per-model config | âœ… | Wired into translation |
| 3.4 | `smallModel` config (default `gpt-5-mini`) | âœ… | |
| 3.5 | `modelReasoningEfforts` config | âœ… | Wired into Responses backend |
| 3.6 | `useFunctionApplyPatch` config toggle | âœ… | Wired into responses handler |
| 3.7 | `compactUseSmallModel` config toggle | âœ… | |
| 3.8 | Default `extraPrompts` auto-merge on startup | âœ… | MergeDefaults() |

### 3B â€” Inbound API Key Auth

| # | Feature | Status | Notes |
|---|---------|--------|-------|
| 3.9 | Auth middleware (x-api-key / Bearer) | âœ… | middleware/auth.go |
| 3.10 | API key normalization (trim, dedup, filter) | âœ… | In config package |
| 3.11 | `WWW-Authenticate` header on 401 | âœ… | Bearer realm |
| 3.12 | OPTIONS / root bypass | âœ… | |

### 3C â€” Quota Optimizations

| # | Feature | Status | Notes |
|---|---------|--------|-------|
| 3.13 | Compact request detection â†’ small model routing | âœ… | isCompactRequest |
| 3.14 | Warmup/probe request detection â†’ small model | âœ… | isWarmupRequest |
| 3.15 | Tool result + text block merging (avoid premium billing) | âœ… | mergeToolResultBlocks |
| 3.16 | Subagent marker detection â†’ force `X-Initiator: agent` | âœ… | detectSubagentMarker |

### 3D â€” Rate Limiting & Manual Approval

| # | Feature | Status | Notes |
|---|---------|--------|-------|
| 3.17 | Time-based rate limiter (reject 429 or wait) | âœ… | middleware/ratelimit.go |
| 3.18 | Interactive CLI approval prompt (403 on reject) | âœ… | middleware/approval.go |

### 3E â€” Token Counting

| # | Feature | Status | Notes |
|---|---------|--------|-------|
| 3.19 | `POST /v1/messages/count_tokens` route | âœ… | |
| 3.20 | Multi-encoding tokenizer (o200k_base, cl100k_base, etc.) | âœ… | chars/4 heuristic (tiktoken-go deferred) |
| 3.21 | Model-specific tokenizer selection | âœ… | Via model capabilities |
| 3.22 | Tool definition token counting | âœ… | Name + desc + params |
| 3.23 | Image token estimation (85 per image) | âœ… | |
| 3.24 | Claude token count 15% inflation | âœ… | Ã—1.15 |
| 3.25 | Fallback to `input_tokens: 1` on error | âœ… | |

### 3F â€” Logging System

| # | Feature | Status | Notes |
|---|---------|--------|-------|
| 3.26 | Per-handler daily log files | âœ… | logger/logger.go |
| 3.27 | Log rotation (delete after 7 days) | âœ… | cleanupLoop |
| 3.28 | Buffered writing (flush interval / buffer size) | âœ… | 100 lines / 1s flush |
| 3.29 | Process cleanup handlers (flush on exit/SIGINT/SIGTERM) | âœ… | signal handler in main |

### 3G â€” Usage Endpoint

| # | Feature | Status | Notes |
|---|---------|--------|-------|
| 3.30 | `GET /usage` route | âœ… | |
| 3.31 | Copilot usage fetch (`GET /copilot_internal/user`) | âœ… | Passthrough to GitHub API |

**Milestone**: Full config system, quota optimizations, rate limiting, logging, and token counting.

---

## Phase 4 â€” CLI Flags & Shell Integration

> Goal: Full CLI experience with all flags and Claude Code launch support.

### 4A â€” CLI Flags

| # | Feature | Status | Notes |
|---|---------|--------|-------|
| 4.1 | `start` command with all flags (`--port`, `--verbose`, `--account-type`, `--manual`, `--rate-limit`, `--wait`, `--github-token`, `--claude-code`, `--show-token`, `--proxy-env`) | âœ… | All 10 flags |
| 4.2 | `auth` command (standalone device-code flow) | âœ… | With --verbose, --show-token |
| 4.3 | `check-usage` command (formatted terminal output) | âœ… | Box-formatted with quotas |
| 4.4 | `debug` command (diagnostic info) | âœ… | Version, runtime, paths, status |
| 4.5 | `debug --json` flag | âœ… | Structured JSON output |

### 4B â€” Shell Integration

| # | Feature | Status | Notes |
|---|---------|--------|-------|
| 4.6 | Cross-platform shell detection (bash/zsh/fish/powershell/cmd) | âœ… | Unix SHELL + Windows wmic |
| 4.7 | Env var export script generation per shell syntax | âœ… | bash/zsh/fish/powershell/cmd |
| 4.8 | Claude Code env vars generation (ANTHROPIC_BASE_URL, etc.) | âœ… | 8 env vars |
| 4.9 | Clipboard auto-copy (fallback to print) | âœ… | pbcopy/xclip/clip |
| 4.10 | Interactive model selection for `--claude-code` | âœ… | Primary + small model |

### 4C â€” Proxy Support

| # | Feature | Status | Notes |
|---|---------|--------|-------|
| 4.11 | Per-URL proxy routing from env vars (HTTP_PROXY, etc.) | âœ… | http.ProxyFromEnvironment |
| 4.12 | `--proxy-env` flag to enable | âœ… | Sets DefaultClient transport |

**Milestone**: Complete CLI with all subcommands, flags, and Claude Code integration.

---

## Phase 5 â€” Deployment & Extras

> Goal: Docker support, web UI dashboard, and remaining polish.

### 5A â€” Docker

| # | Feature | Status | Notes |
|---|---------|--------|-------|
| 5.1 | Multi-stage Dockerfile (Go build) | â¬œ | |
| 5.2 | Health check | â¬œ | |
| 5.3 | `GH_TOKEN` env var support | â¬œ | |
| 5.4 | Volume mount for token persistence | â¬œ | |
| 5.5 | Entrypoint script (`--auth` flag handling) | â¬œ | |
| 5.6 | Docker Compose example | â¬œ | |

### 5B â€” Web UI Dashboard

| # | Feature | Status | Notes |
|---|---------|--------|-------|
| 5.7 | Standalone HTML usage dashboard (embed or serve) | â¬œ | |
| 5.8 | Quota progress bars with color thresholds | â¬œ | |
| 5.9 | Detailed JSON tree view | â¬œ | |
| 5.10 | URL query parameter configuration | â¬œ | |
| 5.11 | Usage viewer URL printed at startup | â¬œ | |

### 5C â€” Remaining Polish

| # | Feature | Status | Notes |
|---|---------|--------|-------|
| 5.12 | `auth` command `--verbose` and `--show-token` flags | â¬œ | |
| 5.13 | Force re-authentication support | â¬œ | |
| 5.14 | Token count calculation + logging in chat completions | â¬œ | |

**Milestone**: Production-ready with Docker deployment and monitoring dashboard.

---

## Architecture Decisions (Go-specific)

| Decision | Choice | Rationale |
|----------|--------|-----------|
| HTTP framework | `go-chi/chi` v5 | Lightweight, idiomatic, great middleware |
| CLI framework | `spf13/cobra` | Most popular Go CLI, subcommand support |
| SSE streaming | `bufio.Scanner` + `http.Flusher` | Native Go streaming |
| JSON handling | `encoding/json` | Standard library |
| Tokenizer | TBD (`tiktoken-go` or similar) | Need multi-encoding support |
| Config | `encoding/json` file read/write | Match original behavior |
| Logging | `log/slog` (stdlib) | Structured logging, zero dependencies |
| UUID | `google/uuid` | For `x-request-id` |
| CORS | `go-chi/cors` | Pairs with chi router |

---

## How to Resume Work

1. Open this file and find the first â¬œ item in the current phase
2. Update its status to ðŸ”¨ when starting
3. Update to âœ… when done
4. Commit at the end of each phase
5. Each phase commit should be verified before pushing
