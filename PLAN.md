# Copilot Proxy Go â€” Implementation Plan

> A Go rewrite of [caozhiyuan/copilot-api](https://github.com/caozhiyuan/copilot-api/tree/all).
> Turns GitHub Copilot into an OpenAI / Anthropic compatible API server.

## Status Legend

- â¬œ Not started
- ðŸ”¨ In progress
- âœ… Completed
- â­ï¸ Skipped

---

## Phase 1 â€” Core Foundation

> Goal: A working server that can authenticate with GitHub, fetch models, and proxy
> one translation path (Chat Completions passthrough) end-to-end.

| # | Feature | Status | Notes |
|---|---------|--------|-------|
| 1.1 | Project scaffolding (`go.mod`, directory structure, `main.go`) | âœ… | chi + cobra |
| 1.2 | Global state management (tokens, models, config, flags) | âœ… | Singleton with sync.RWMutex |
| 1.3 | File system paths (`~/.local/share/copilot-api/`) | âœ… | `EnsurePaths()` |
| 1.4 | GitHub OAuth device-code flow (client ID, scope `read:user`) | âœ… | |
| 1.5 | Device code polling with interval | âœ… | With slow_down handling |
| 1.6 | GitHub token persistence to disk | âœ… | `0600` permissions |
| 1.7 | Copilot token fetch (`GET /copilot_internal/v2/token`) | âœ… | |
| 1.8 | Copilot token auto-refresh timer | âœ… | Goroutine with `refresh_in - 60s` |
| 1.9 | User identity logging (`GET /user`) | âœ… | |
| 1.10 | Dynamic Copilot base URL per account type | âœ… | individual/business/enterprise |
| 1.11 | VS Code version fetching (AUR scrape + hardcoded fallback) | âœ… | 5s timeout, regex parse |
| 1.12 | Copilot request headers builder (User-Agent, editor-version, etc.) | âœ… | |
| 1.13 | `X-Initiator` header (agent/user) | âœ… | |
| 1.14 | `x-request-id: {uuid}` per request | âœ… | google/uuid |
| 1.15 | HTTP server setup (e.g. `net/http` + router like `chi` or `echo`) | âœ… | go-chi/chi v5 |
| 1.16 | Request logging middleware | âœ… | slog-based |
| 1.17 | CORS middleware | âœ… | go-chi/cors |
| 1.18 | Health check `GET /` â†’ "Server running" | âœ… | |
| 1.19 | `GET /models` + `/v1/models` â€” model listing | âœ… | |
| 1.20 | Model capabilities parsing & caching at startup | âœ… | |
| 1.21 | `GET /models` service â€” fetch from Copilot API | âœ… | |
| 1.22 | `POST /chat/completions` + `/v1/chat/completions` â€” passthrough | âœ… | |
| 1.23 | `max_tokens` auto-fill from model capabilities | âœ… | |
| 1.24 | Agent/user initiator detection (chat completions) | âœ… | Last message role check |
| 1.25 | Non-streaming response passthrough | âœ… | |
| 1.26 | SSE streaming passthrough | âœ… | bufio.Scanner + http.Flusher |
| 1.27 | `HTTPError` type + `forwardError` utility | âœ… | JSON error parsing |
| 1.28 | `GET /token` â€” expose current Copilot bearer token | âœ… | |
| 1.29 | Basic `start` command (port, github-token, account-type flags only) | âœ… | +verbose, +show-token |

**Milestone**: Can authenticate, list models, and proxy OpenAI Chat Completions requests.

---

## Phase 2 â€” Full API Translation

> Goal: Support all 3 backend routing paths for the Anthropic Messages endpoint,
> plus the OpenAI Responses and Embeddings endpoints.

### 2A â€” Anthropic Messages â†’ Chat Completions Backend

| # | Feature | Status | Notes |
|---|---------|--------|-------|
| 2.1 | `POST /v1/messages` route registration | â¬œ | |
| 2.2 | 3-way backend routing logic (messages/responses/chat-completions) | â¬œ | Based on `supported_endpoints` |
| 2.3 | System prompt translation (string or array â†’ system message) | â¬œ | |
| 2.4 | Extra prompt injection from config per model | â¬œ | |
| 2.5 | User message translation (split tool_result into tool role) | â¬œ | |
| 2.6 | Assistant message translation (tool_use â†’ tool_calls, thinking â†’ reasoning) | â¬œ | |
| 2.7 | Image content handling (base64 â†’ data URI) | â¬œ | |
| 2.8 | Tool definition translation (input_schema â†’ parameters) | â¬œ | |
| 2.9 | Tool choice translation (auto/any/tool/none) | â¬œ | |
| 2.10 | Model name normalization (strip version suffixes) | â¬œ | |
| 2.11 | Non-streaming response translation (OpenAI â†’ Anthropic) | â¬œ | |
| 2.12 | Stop reason mapping (stopâ†’end_turn, etc.) | â¬œ | |
| 2.13 | Streaming translation â€” state machine (SSE chunks â†’ Anthropic events) | â¬œ | Most complex piece |
| 2.14 | Thinking text streaming as thinking blocks | â¬œ | |
| 2.15 | Reasoning opaque streaming with placeholder + signature | â¬œ | |
| 2.16 | Tool call streaming with `input_json_delta` | â¬œ | |
| 2.17 | Multi-tool-call streaming state | â¬œ | |
| 2.18 | Usage / cache token passthrough | â¬œ | |
| 2.19 | Error event translation | â¬œ | |
| 2.20 | Interleaved thinking protocol injection | â¬œ | XML system prompt + system-reminder |
| 2.21 | Thinking budget calculation (clamp min/max) | â¬œ | |
| 2.22 | Thinking block filtering for Claude models | â¬œ | Empty, "Thinking...", `@` in signature |
| 2.23 | Edge cases: content after thinking, reasoning_text during content block | â¬œ | |
| 2.24 | `copilot-vision-request: true` header when images detected | â¬œ | |
| 2.25 | `"Thinking..."` placeholder for opencode compatibility | â¬œ | |
| 2.26 | Cache read token separation (Anthropic billing model) | â¬œ | |

### 2B â€” Anthropic Messages â†’ Responses API Backend

| # | Feature | Status | Notes |
|---|---------|--------|-------|
| 2.27 | Full message/tool/system â†’ Responses format translation | â¬œ | |
| 2.28 | Temperature forced to 1 for reasoning models | â¬œ | |
| 2.29 | `max_output_tokens` minimum 12800 | â¬œ | |
| 2.30 | Reasoning effort from config | â¬œ | |
| 2.31 | Reasoning config (`include`, `store`, `parallel_tool_calls`) | â¬œ | |
| 2.32 | User ID parsing for `safety_identifier` + `prompt_cache_key` | â¬œ | |
| 2.33 | Codex phase assignment (`commentary`/`final_answer` for gpt-5.3-codex) | â¬œ | |
| 2.34 | Thinking block â†’ reasoning item conversion (signature `@` encoding) | â¬œ | |
| 2.35 | Tool result â†’ `function_call_output` conversion | â¬œ | |
| 2.36 | Image content â†’ `input_image` conversion | â¬œ | |
| 2.37 | Non-streaming Responses â†’ Anthropic translation | â¬œ | |
| 2.38 | Streaming Responses â†’ Anthropic SSE translation | â¬œ | |
| 2.39 | Infinite whitespace detection guard (20 char limit) | â¬œ | |
| 2.40 | Stream completion detection | â¬œ | |
| 2.41 | Function call argument parsing with fallback | â¬œ | |

### 2C â€” Native Messages API Passthrough

| # | Feature | Status | Notes |
|---|---------|--------|-------|
| 2.42 | Direct forwarding for models supporting `/v1/messages` | â¬œ | |
| 2.43 | Thinking block filtering before forwarding | â¬œ | |
| 2.44 | Adaptive thinking support with effort mapping | â¬œ | |
| 2.45 | `anthropic-beta` header filtering (remove `claude-code-20250219`) | â¬œ | |
| 2.46 | `anthropic-beta` auto-injection for thinking | â¬œ | |
| 2.47 | Vision detection + header | â¬œ | |
| 2.48 | Streaming / non-streaming passthrough | â¬œ | |

### 2D â€” OpenAI Responses Endpoint (Passthrough)

| # | Feature | Status | Notes |
|---|---------|--------|-------|
| 2.49 | `POST /responses` + `/v1/responses` route | â¬œ | |
| 2.50 | Model support validation (400 if unsupported) | â¬œ | |
| 2.51 | `apply_patch` custom tool â†’ function tool conversion | â¬œ | |
| 2.52 | `web_search` tool removal | â¬œ | |
| 2.53 | Stream ID synchronization (fix `@ai-sdk/openai` crashes) | â¬œ | |
| 2.54 | `service_tier` nullification | â¬œ | |
| 2.55 | Vision detection in Responses payloads | â¬œ | |
| 2.56 | Agent initiator detection (Responses) | â¬œ | |
| 2.57 | Non-streaming / streaming passthrough | â¬œ | |

### 2E â€” Embeddings Endpoint

| # | Feature | Status | Notes |
|---|---------|--------|-------|
| 2.58 | `POST /embeddings` + `/v1/embeddings` route | â¬œ | |
| 2.59 | Embeddings passthrough to Copilot | â¬œ | |

**Milestone**: Full Anthropic Messages API compatibility with all 3 backends,
plus OpenAI Responses and Embeddings passthrough.

---

## Phase 3 â€” Optimizations & Utilities

> Goal: Quota-saving logic, rate limiting, token counting, logging, and config system.

### 3A â€” Configuration System

| # | Feature | Status | Notes |
|---|---------|--------|-------|
| 3.1 | JSON config file (`config.json`) auto-creation with defaults | â¬œ | |
| 3.2 | `auth.apiKeys` config option | â¬œ | |
| 3.3 | `extraPrompts` per-model config | â¬œ | |
| 3.4 | `smallModel` config (default `gpt-5-mini`) | â¬œ | |
| 3.5 | `modelReasoningEfforts` config | â¬œ | |
| 3.6 | `useFunctionApplyPatch` config toggle | â¬œ | |
| 3.7 | `compactUseSmallModel` config toggle | â¬œ | |
| 3.8 | Default `extraPrompts` auto-merge on startup | â¬œ | |

### 3B â€” Inbound API Key Auth

| # | Feature | Status | Notes |
|---|---------|--------|-------|
| 3.9 | Auth middleware (x-api-key / Bearer) | â¬œ | |
| 3.10 | API key normalization (trim, dedup, filter) | â¬œ | |
| 3.11 | `WWW-Authenticate` header on 401 | â¬œ | |
| 3.12 | OPTIONS / root bypass | â¬œ | |

### 3C â€” Quota Optimizations

| # | Feature | Status | Notes |
|---|---------|--------|-------|
| 3.13 | Compact request detection â†’ small model routing | â¬œ | |
| 3.14 | Warmup/probe request detection â†’ small model | â¬œ | |
| 3.15 | Tool result + text block merging (avoid premium billing) | â¬œ | |
| 3.16 | Subagent marker detection â†’ force `X-Initiator: agent` | â¬œ | |

### 3D â€” Rate Limiting & Manual Approval

| # | Feature | Status | Notes |
|---|---------|--------|-------|
| 3.17 | Time-based rate limiter (reject 429 or wait) | â¬œ | |
| 3.18 | Interactive CLI approval prompt (403 on reject) | â¬œ | |

### 3E â€” Token Counting

| # | Feature | Status | Notes |
|---|---------|--------|-------|
| 3.19 | `POST /v1/messages/count_tokens` route | â¬œ | |
| 3.20 | Multi-encoding tokenizer (o200k_base, cl100k_base, etc.) | â¬œ | Use Go tokenizer lib |
| 3.21 | Model-specific tokenizer selection | â¬œ | |
| 3.22 | Tool definition token counting | â¬œ | |
| 3.23 | Image token estimation (85 per image) | â¬œ | |
| 3.24 | Claude token count 15% inflation | â¬œ | |
| 3.25 | Fallback to `input_tokens: 1` on error | â¬œ | |

### 3F â€” Logging System

| # | Feature | Status | Notes |
|---|---------|--------|-------|
| 3.26 | Per-handler daily log files | â¬œ | |
| 3.27 | Log rotation (delete after 7 days) | â¬œ | |
| 3.28 | Buffered writing (flush interval / buffer size) | â¬œ | |
| 3.29 | Process cleanup handlers (flush on exit/SIGINT/SIGTERM) | â¬œ | |

### 3G â€” Usage Endpoint

| # | Feature | Status | Notes |
|---|---------|--------|-------|
| 3.30 | `GET /usage` route | â¬œ | |
| 3.31 | Copilot usage fetch (`GET /copilot_internal/user`) | â¬œ | |

**Milestone**: Full config system, quota optimizations, rate limiting, logging, and token counting.

---

## Phase 4 â€” CLI Flags & Shell Integration

> Goal: Full CLI experience with all flags and Claude Code launch support.

### 4A â€” CLI Flags

| # | Feature | Status | Notes |
|---|---------|--------|-------|
| 4.1 | `start` command with all flags (`--port`, `--verbose`, `--account-type`, `--manual`, `--rate-limit`, `--wait`, `--github-token`, `--claude-code`, `--show-token`, `--proxy-env`) | â¬œ | Use `cobra` or `urfave/cli` |
| 4.2 | `auth` command (standalone device-code flow) | â¬œ | |
| 4.3 | `check-usage` command (formatted terminal output) | â¬œ | |
| 4.4 | `debug` command (diagnostic info) | â¬œ | |
| 4.5 | `debug --json` flag | â¬œ | |

### 4B â€” Shell Integration

| # | Feature | Status | Notes |
|---|---------|--------|-------|
| 4.6 | Cross-platform shell detection (bash/zsh/fish/powershell/cmd) | â¬œ | |
| 4.7 | Env var export script generation per shell syntax | â¬œ | |
| 4.8 | Claude Code env vars generation (ANTHROPIC_BASE_URL, etc.) | â¬œ | |
| 4.9 | Clipboard auto-copy (fallback to print) | â¬œ | |
| 4.10 | Interactive model selection for `--claude-code` | â¬œ | |

### 4C â€” Proxy Support

| # | Feature | Status | Notes |
|---|---------|--------|-------|
| 4.11 | Per-URL proxy routing from env vars (HTTP_PROXY, etc.) | â¬œ | Go's `http.ProxyFromEnvironment` |
| 4.12 | `--proxy-env` flag to enable | â¬œ | |

**Milestone**: Complete CLI with all subcommands, flags, and Claude Code integration.

---

## Phase 5 â€” Deployment & Extras

> Goal: Docker support, web UI dashboard, and remaining polish.

### 5A â€” Docker

| # | Feature | Status | Notes |
|---|---------|--------|-------|
| 5.1 | Multi-stage Dockerfile (Go build) | â¬œ | |
| 5.2 | Health check | â¬œ | |
| 5.3 | `GH_TOKEN` env var support | â¬œ | |
| 5.4 | Volume mount for token persistence | â¬œ | |
| 5.5 | Entrypoint script (`--auth` flag handling) | â¬œ | |
| 5.6 | Docker Compose example | â¬œ | |

### 5B â€” Web UI Dashboard

| # | Feature | Status | Notes |
|---|---------|--------|-------|
| 5.7 | Standalone HTML usage dashboard (embed or serve) | â¬œ | |
| 5.8 | Quota progress bars with color thresholds | â¬œ | |
| 5.9 | Detailed JSON tree view | â¬œ | |
| 5.10 | URL query parameter configuration | â¬œ | |
| 5.11 | Usage viewer URL printed at startup | â¬œ | |

### 5C â€” Remaining Polish

| # | Feature | Status | Notes |
|---|---------|--------|-------|
| 5.12 | `auth` command `--verbose` and `--show-token` flags | â¬œ | |
| 5.13 | Force re-authentication support | â¬œ | |
| 5.14 | Token count calculation + logging in chat completions | â¬œ | |

**Milestone**: Production-ready with Docker deployment and monitoring dashboard.

---

## Architecture Decisions (Go-specific)

| Decision | Choice | Rationale |
|----------|--------|-----------|
| HTTP framework | `go-chi/chi` v5 | Lightweight, idiomatic, great middleware |
| CLI framework | `spf13/cobra` | Most popular Go CLI, subcommand support |
| SSE streaming | `bufio.Scanner` + `http.Flusher` | Native Go streaming |
| JSON handling | `encoding/json` | Standard library |
| Tokenizer | TBD (`tiktoken-go` or similar) | Need multi-encoding support |
| Config | `encoding/json` file read/write | Match original behavior |
| Logging | `log/slog` (stdlib) | Structured logging, zero dependencies |
| UUID | `google/uuid` | For `x-request-id` |
| CORS | `go-chi/cors` | Pairs with chi router |

---

## How to Resume Work

1. Open this file and find the first â¬œ item in the current phase
2. Update its status to ðŸ”¨ when starting
3. Update to âœ… when done
4. Commit at the end of each phase
5. Each phase commit should be verified before pushing
